{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses an autoencoder to approximate the habituation/dishabituation process\n",
    "An autoencoder is afixed ontop of the pre-trained model \n",
    "LiMA stim are run through it\n",
    "\n",
    "Author: VAYZENB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os, argparse\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import cornet\n",
    "from torchvision import datasets\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "from LoadFrames import LoadFrames\n",
    "from statistics import mean\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ['Exp1', 'Exp2']\n",
    "\n",
    "skel = [['23','31', '26'],['31_0', '31_50']]\n",
    "SF = ['Skel', 'Bulge']\n",
    "modelType = ['AlexNet_SN', 'ResNet_SN', 'AlexNet_IN', 'ResNet_IN', 'CorNet_Z', 'CorNet_S','SayCam']\n",
    "\n",
    "hab_min = 4 #minimum number of habituation trials to \n",
    "batch_num = 10 #how many frames to use at a time\n",
    "#exp = ['Exp1']\n",
    "#skel=[['26']]\n",
    "#SF = ['Skel']\n",
    "modelType = ['ResNet_SN',  'ResNet_IN', 'CorNet_Z', 'CorNet_S','SayCam']\n",
    "\n",
    "#Transformations for ImageNet\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                             std=[0.229, 0.224, 0.225])])\n",
    "# specify loss function\n",
    "criterion = nn.MSELoss()\n",
    "#criterion.cuda()\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "#Gets feats for CorNet models\n",
    "def _store_feats(layer, inp, output):\n",
    "    \"\"\"An ugly but effective way of accessing intermediate model features\n",
    "    \"\"\"   \n",
    "    output = output\n",
    "    _model_feats.append(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(modelType_):\n",
    "    #select model to run\n",
    "    if modelType_ == 'AlexNet_IN':\n",
    "        model = torchvision.models.alexnet(pretrained=True)\n",
    "        new_classifier = nn.Sequential(*list(model.classifier.children())[:-2])\n",
    "        model.classifier = new_classifier #replace model classifier with stripped version\n",
    "        layer = \"fc7\"\n",
    "        actNum = 4096\n",
    "        \n",
    "    elif modelType_ == 'ResNet_IN':\n",
    "        model = torchvision.models.resnet50(pretrained=True)\n",
    "        model = nn.Sequential(*list(model.children())[:-1])\n",
    "        layer = \"avgpool\"\n",
    "        actNum = 2048\n",
    "                \n",
    "    elif modelType_ == 'AlexNet_SN':\n",
    "        model = torchvision.models.alexnet(pretrained=False)\n",
    "        checkpoint = torch.load('Weights/ShapeNet_AlexNet_Weights.pth.tar')\n",
    "        model.load_state_dict(checkpoint)\n",
    "        new_classifier = nn.Sequential(*list(model.classifier.children())[:-2])\n",
    "        model.classifier = new_classifier #replace model classifier with stripped version\n",
    "        layer = \"fc7\"\n",
    "        actNum = 4096\n",
    "        \n",
    "    elif modelType_ == 'ResNet_SN':\n",
    "        model = torchvision.models.resnet50(pretrained=False)\n",
    "        checkpoint = torch.load('Weights/ShapeNet_ResNet50_Weights.pth.tar')\n",
    "        model.load_state_dict(checkpoint)\n",
    "        model = nn.Sequential(*list(model.children())[:-1])\n",
    "        \n",
    "        layer = \"avgpool\"\n",
    "        actNum = 2048\n",
    "    \n",
    "    elif modelType_ == 'CorNet_Z':\n",
    "        model = getattr(cornet, 'cornet_z')\n",
    "        model = model(pretrained=False, map_location='gpu')\n",
    "        \n",
    "        layer = \"avgpool\"\n",
    "        actNum = 512\n",
    "    \n",
    "        try:\n",
    "            m = model.module\n",
    "        except:\n",
    "            m = model\n",
    "        model_layer = getattr(getattr(m, 'decoder'), layer)\n",
    "        model_layer.register_forward_hook(_store_feats)\n",
    "\n",
    "    elif modelType[mm] == 'CorNet_S':\n",
    "        model = getattr(cornet, 'cornet_s')\n",
    "        model = model(pretrained=False, map_location='gpu')\n",
    "        \n",
    "        layer = \"avgpool\"\n",
    "        actNum = 512        \n",
    "\n",
    "        try:\n",
    "            m = model.module\n",
    "        except:\n",
    "            m = model\n",
    "        \n",
    "        model_layer = getattr(getattr(m, 'decoder'), layer)\n",
    "        model_layer.register_forward_hook(_store_feats)\n",
    "\n",
    "    elif modelType[mm] == 'SayCam':\n",
    "        model = torchvision.models.resnext50_32x4d(pretrained=False)\n",
    "        #model = torch.nn.DataParallel(model)\n",
    "        #model.fc = torch.nn.Linear(in_features=2048, out_features=n_out, bias=True)\n",
    "        checkpoint = torch.load('Weights/SayCam_ResNext_Weights.pth.tar')\n",
    "        model.load_state_dict(checkpoint)\n",
    "        \n",
    "        actNum = 2048\n",
    "\n",
    "        model = nn.Sequential(*list(model.children())[:-1])\n",
    "        \n",
    "    return model, actNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 43.992868177833095\n",
      "1 2.2917115043608414\n",
      "2 0.16452059873770322\n",
      "3 0.08195306533466905\n",
      "4 0.07833101388607774 11.632763336566576 0.07833101388607774\n",
      "5 0.05536299143286963 11.632763336566576 0.06684700265947369\n",
      "6 0.061552243442424846 11.632763336566576 0.061552243442424846\n",
      "7 0.05955404007146435 11.632763336566576 0.06370007220820914\n",
      "8 0.06776196665821536 11.632763336566576 0.06105781040124355\n",
      "Saving model ResNet_SN Figure_23_Skel 8 11.632763336566576 0.06105781040124355\n",
      "0 72.05853323109689\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-cb5d0e3caa76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m                         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                         \u001b[0;31m#print(train_loss, loss.item()*frames.size(0), n)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for ee in range(0,len(exp)):\n",
    "    hab_data = np.empty(((len(skel[ee]) * len(SF) *len(modelType)),12), dtype = object)\n",
    "    hn = 0\n",
    "    for mm in range(0, len(modelType)):\n",
    "        \n",
    "        \n",
    "        encoder, in_feat = load_model(modelType[mm])\n",
    "        \n",
    "        if modelType[mm] == 'CorNet_Z' or modelType[mm] == 'CorNet_S':\n",
    "            try:\n",
    "                m = encoder.module\n",
    "            except:\n",
    "                m = encoder\n",
    "            model_layer = getattr(getattr(m, 'decoder'), \"avgpool\")\n",
    "            model_layer.register_forward_hook(_store_feats)\n",
    "\n",
    "        encoder = encoder.cuda()\n",
    "        encoder.eval()\n",
    "    \n",
    "        for sk in range(0,len(skel[ee])):\n",
    "            for sf in SF:\n",
    "                torch.cuda.empty_cache() #clear GPU memory\n",
    "                hab_dataset = LoadFrames(f'Frames/Figure_{skel[ee][sk]}_{sf}', transform=transform)\n",
    "                trainloader = torch.utils.data.DataLoader(hab_dataset, batch_size=batch_num, shuffle=True, num_workers = 0, pin_memory=True)\n",
    "\n",
    "                early_hab = 0.0\n",
    "                late_hab = []\n",
    "                \n",
    "                #Reset decoder for every object (i.e., make it like a fresh hab session)\n",
    "                #Create decoder\n",
    "                decoder = nn.Sequential(nn.ReLU(), nn.ConvTranspose2d(in_feat, 3, 224))\n",
    "                decoder = decoder.cuda()\n",
    "                decoder.eval()\n",
    "                decoder.train()\n",
    "                \n",
    "                #set up optimzer\n",
    "                #optimizer = torch.optim.SGD(decoder.parameters(), lr=0.01, momentum=0.9)\n",
    "                optimizer = torch.optim.Adam(decoder.parameters(), lr=0.01)\n",
    "                for ep in range(0,epochs):\n",
    "                    train_loss = 0.0 \n",
    "                    total_loss =0.0\n",
    "                    n = 0\n",
    "                    for frames in trainloader:\n",
    "                        frames = frames.cuda()\n",
    "                        \n",
    "                        if modelType[mm] == 'CorNet_Z' or modelType[mm] == 'CorNet_S':\n",
    "                            _model_feats = []\n",
    "                            encoder(frames)\n",
    "                            encode_out = _model_feats[0]\n",
    "                            #print(encode_out.shape)\n",
    "                        elif modelType[mm] == 'AlexNet_SN' or modelType[mm] == 'AlexNet_IN':\n",
    "                            encode_out = encoder(frames) #Get encoder features\n",
    "                            encode_out = encode_out[:,:, None, None]\n",
    "                        else:\n",
    "                            encode_out = encoder(frames) #Get encoder features\n",
    "                        \n",
    "                        optimizer.zero_grad() #zero out gradients from previous epoch\n",
    "                        \n",
    "                        decode_out = decoder(encode_out) #Run features through decoder\n",
    "                                                \n",
    "                        loss = criterion(decode_out, frames) #Calculate loss\n",
    "\n",
    "                        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "                        loss.backward()\n",
    "                        # perform a single optimization step (parameter update)\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                        \n",
    "                        train_loss += (loss.item()*frames.size(0))\n",
    "                        n = n +1\n",
    "                        #print(train_loss, loss.item()*frames.size(0), n)\n",
    "\n",
    "                    total_loss = train_loss/n\n",
    "\n",
    "                    if ep < hab_min:\n",
    "                        early_hab += total_loss #track loss for the first 4 trials\n",
    "                        print(ep, total_loss)\n",
    "                    elif ep >= hab_min:\n",
    "                        hab_start = early_hab / hab_min #Determine habituation criterion\n",
    "                        late_hab.append(total_loss) #add current loss to habituation\n",
    "                        hab_end = mean(late_hab[(len(late_hab)-4):len(late_hab)]) #calcualte mean of last 4 hab trials\n",
    "\n",
    "                        print(ep, total_loss, hab_start, hab_end)\n",
    "                        if hab_end < (hab_start/2) and ep >= int(hab_min *2): #test if habituated\n",
    "                            break\n",
    "                \n",
    "                hab_data[hn,0] =  modelType[mm]\n",
    "                hab_data[hn,1] =  skel[ee][sk]\n",
    "                hab_data[hn,2] =  sf\n",
    "                hab_data[hn,3] =  ep\n",
    "                hab_data[hn,4] =  hab_start\n",
    "                hab_data[hn,5] =  hab_end\n",
    "                \n",
    "                print('Saving model', modelType[mm], f'Figure_{skel[ee][sk]}_{sf}', ep, hab_start, hab_end)                \n",
    "                torch.save(decoder.state_dict(), f'Weights/decoder/{exp[ee]}_{modelType[mm]}_Figure_{skel[ee][sk]}_{sf}.pt')\n",
    "                np.save(f'Weights/decoder/{exp[ee]}_Summary.npy', hab_data)\n",
    "                hn = hn + 1\n",
    "                del decoder\n",
    "    del encoder\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = transforms.Resize((224, 224))\n",
    "#normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                 std=[0.229, 0.224, 0.225])\n",
    "#to_tensor = transforms.ToTensor()\n",
    "def image_loader(image_name):\n",
    "    \"\"\"load image, returns cuda tensor\"\"\"\n",
    "    image = Image.open(image_name).convert(\"RGB\")\n",
    "    #image = Variable(normalize(to_tensor(scaler(image))).unsqueeze(0))\n",
    "    image = transform(image).unsqueeze(0)\n",
    "    \n",
    "    return image     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load sample image\n",
    "IM = image_loader('Frames/Figure_26_Skel/Figure_26_Skel_150.jpg')\n",
    "IM = IM.cuda()\n",
    "print(IM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder = nn.Sequential(nn.ReLU(), nn.ConvTranspose2d(in_feat, 3, 224))\n",
    "#decoder = decoder.cuda()\n",
    "decoder.eval()\n",
    "\n",
    "out=encoder(IM)\n",
    "out = decoder(out)\n",
    "loss = criterion(out, IM)\n",
    "print(loss.item()*IM.size(0))\n",
    "#out = out.squeeze(0)\n",
    "#print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here on is image preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out.squeeze(0)\n",
    "print(out.shape)\n",
    "inv_normalize = transforms.Normalize(\n",
    "   mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
    "   std=[1/0.229, 1/0.224, 1/0.225]\n",
    ")\n",
    "\n",
    "output = inv_normalize(out)\n",
    "output = output.cpu().detach()\n",
    "plt.imshow(output.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM = IM.squeeze(0)\n",
    "IM = inv_normalize(IM)\n",
    "IM = IM.cpu().detach()\n",
    "plt.imshow(IM.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here on is image preview"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
