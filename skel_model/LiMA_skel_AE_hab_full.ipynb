{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses an autoencoder to approximate the habituation/dishabituation process\n",
    "An autoencoder is afixed ontop of the pre-trained model \n",
    "LiMA stim are run through it\n",
    "\n",
    "Author: VAYZENB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dir = '/home/vayzenbe/GitHub_Repos/LiMA'\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, f'{curr_dir}')\n",
    "import os, argparse\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "from LoadFrames import LoadFrames\n",
    "from statistics import mean\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ['Exp1']\n",
    "\n",
    "skel = [['23','31','26'],['31_0', '31_50']]\n",
    "skel = [['23'],['31_0', '31_50']]\n",
    "SF = ['Skel', 'Bulge']\n",
    "#modelType = ['AlexNet_SN', 'ResNet_SN', 'AlexNet_IN', 'ResNet_IN', 'CorNet_Z', 'CorNet_S','SayCam']\n",
    "modelType = 'skel'\n",
    "batch_num = 10\n",
    "#hab_min = 4 #minimum number of habituation trials to \n",
    "#batch_num = 10 #how many frames to use at a time\n",
    "#exp = ['Exp1']\n",
    "#skel=[['23']]\n",
    "#SF = ['Skel']\n",
    "#modelType = ['ResNet_SN',  'ResNet_IN', 'CorNet_Z', 'CorNet_S','SayCam']\n",
    "\n",
    "#Transformations for ImageNet\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                             std=[0.229, 0.224, 0.225])])\n",
    "inv_normalize = transforms.Normalize(\n",
    "   mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],std=[1/0.229, 1/0.224, 1/0.225])\n",
    "# specify loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "hab_min = 3 #minimum number of habituation trials to \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_decoder():\n",
    "    #decoder = nn.Sequential(nn.Conv2d(3,1024,kernel_size=3, stride=2), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2, padding=1), nn.AdaptiveAvgPool2d(1),nn.ReLU(), nn.ConvTranspose2d(1024, 3, 224))\n",
    "    decoder = nn.Sequential(nn.Conv2d(3,1024,kernel_size=1, stride=1), nn.ReLU(), nn.AdaptiveAvgPool2d(1),nn.ReLU(), nn.ConvTranspose2d(1024, 3, 224))\n",
    "    decoder = decoder.cuda()\n",
    "    \n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, epoch, optimizer, loss, file_path):\n",
    "\n",
    "    print('Saving model ...')\n",
    "    #torch.save(model.state_dict(), f'{weights_dir}/cornet_classify_{cond}_{epoch}.pt')\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "        }, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_recon(out_,sk_,sf_, model, stim):\n",
    "    \n",
    "    fig,ax = plt.subplots(1)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    # Show the image\n",
    "    #ax.imshow(im)\n",
    "\n",
    "    out_ = out_.squeeze(0)\n",
    "    out_ = inv_normalize(out_)\n",
    "    out_ = out_.cpu().detach()\n",
    "    ax.imshow(out_.permute(1, 2, 0))\n",
    "    plt.axis('off')\n",
    "    #print(f'Results/AE/recon/{model}_{fig_fig_}.png')\n",
    "    plt.savefig(f'{curr_dir}/Results/AE/recon/{model}_{stim}_skel.png', bbox_inches='tight', pad_inches = 0, dpi=150)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 45.267816384633385\n",
      "1 18.52653483549754\n",
      "2 6.556087483962377\n",
      "3 11.293734709421793 23.450146234697765 11.293734709421793\n",
      "4 2.2855724145968757 23.450146234697765 6.789653562009335\n",
      "5 5.869081219037374 23.450146234697765 5.869081219037374\n",
      "6 1.3280391444762547 23.450146234697765 5.194106871883074\n",
      "Saving model Figure_23_Skel 6 23.450146234697765 5.194106871883074\n",
      "Saving model ...\n",
      "0 40.240066846211754\n",
      "1 13.503392313917479\n",
      "2 5.8774857223033905\n",
      "3 8.695497115453085 19.873648294144207 8.695497115453085\n",
      "4 1.623819147547086 19.873648294144207 5.159658131500086\n",
      "5 4.540304938952128 19.873648294144207 4.540304938952128\n",
      "6 1.3903189202149708 19.873648294144207 4.062485030541818\n",
      "Saving model Figure_23_Bulge 6 19.873648294144207 4.062485030541818\n",
      "Saving model ...\n",
      "0 44.506778717041016\n",
      "1 17.136107335488003\n",
      "2 6.112465212742488\n",
      "3 10.473796526590982 22.58511708842384 10.473796526590982\n",
      "4 1.8859785546859105 22.58511708842384 6.179887540638447\n",
      "5 5.417716999848683 22.58511708842384 5.417716999848683\n",
      "6 1.3122791796922684 22.58511708842384 4.772442815204461\n",
      "Saving model Figure_31_Skel 6 22.58511708842384 4.772442815204461\n",
      "Saving model ...\n",
      "0 49.65421915054321\n",
      "1 21.06082131465276\n",
      "2 6.567488461732864\n",
      "3 12.364198962847391 25.760842975642944 12.364198962847391\n",
      "4 2.069952959815661 25.760842975642944 7.217075961331526\n",
      "5 6.28649115562439 25.760842975642944 6.28649115562439\n",
      "6 1.345237245162328 25.760842975642944 5.516470080862442\n",
      "Saving model Figure_31_Bulge 6 25.760842975642944 5.516470080862442\n",
      "Saving model ...\n",
      "0 51.48988723754883\n",
      "1 22.776809831460316\n",
      "2 6.744589830438296\n",
      "3 13.093878825505575 27.003762299815815 13.093878825505575\n",
      "4 2.1649301052093506 27.003762299815815 7.629404465357463\n",
      "5 6.668814619382222 27.003762299815815 6.668814619382222\n",
      "6 1.3991830001274745 27.003762299815815 5.831701637556155\n",
      "Saving model Figure_26_Skel 6 27.003762299815815 5.831701637556155\n",
      "Saving model ...\n",
      "0 40.41311105092367\n",
      "1 13.669894337654114\n",
      "2 5.850278635819753\n",
      "3 8.813307086626688 19.977761341465847 8.813307086626688\n",
      "4 1.658426709473133 19.977761341465847 5.235866898049911\n",
      "5 4.613065918286641 19.977761341465847 4.613065918286641\n",
      "6 1.1629646892348926 19.977761341465847 4.061941100905338\n",
      "Saving model Figure_26_Bulge 6 19.977761341465847 4.061941100905338\n",
      "Saving model ...\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "habituate\n",
    "'''\n",
    "\n",
    "\n",
    "for ee in range(0,len(exp)):\n",
    "    hab_data = np.empty(((len(skel[ee]) * len(SF) *len(modelType)),11), dtype = object)\n",
    "    hn = 0\n",
    "\n",
    "\n",
    "    for sk in range(0,len(skel[ee])):\n",
    "        for sf in SF:\n",
    "            torch.cuda.empty_cache() #clear GPU memory\n",
    "            hab_dataset = LoadFrames(f'skels/Figure_{skel[ee][sk]}_{sf}', transform=transform)\n",
    "            trainloader = torch.utils.data.DataLoader(hab_dataset, batch_size=batch_num, shuffle=True, num_workers = 2, pin_memory=True)\n",
    "\n",
    "            early_hab = 0.0\n",
    "            late_hab = []\n",
    "\n",
    "            #Reset decoder for every object (i.e., make it like a fresh hab session)\n",
    "            #Create decoder\n",
    "            decoder = define_decoder()\n",
    "            \n",
    "            decoder.train()\n",
    "\n",
    "            #set up optimzer\n",
    "            optimizer = torch.optim.Adam(decoder.parameters(), lr=0.01)\n",
    "            for ep in range(0,epochs):\n",
    "                train_loss = 0.0 \n",
    "                total_loss =0.0\n",
    "                n = 0\n",
    "                for frames in trainloader:\n",
    "                    frames = frames.cuda()\n",
    "\n",
    "\n",
    "                    optimizer.zero_grad() #zero out gradients from previous epoch\n",
    "\n",
    "                    decode_out = decoder(frames) #Run features through decoder\n",
    "\n",
    "                    loss = criterion(decode_out, frames) #Calculate loss\n",
    "\n",
    "                    # backward pass: compute gradient of the loss with respect to model parameters\n",
    "                    loss.backward()\n",
    "                    # perform a single optimization step (parameter update)\n",
    "                    optimizer.step()\n",
    "\n",
    "\n",
    "                    train_loss += (loss.item()*frames.size(0))\n",
    "                    n = n +1\n",
    "                    #print(train_loss, loss.item()*frames.size(0), n)\n",
    "\n",
    "                total_loss = train_loss/n\n",
    "\n",
    "                if ep < hab_min:\n",
    "                    early_hab += total_loss #track loss for the first 4 trials\n",
    "                    print(ep, total_loss)\n",
    "                elif ep >= hab_min:\n",
    "                    hab_start = early_hab / hab_min #Determine habituation criterion\n",
    "                    late_hab.append(total_loss) #add current loss to habituation\n",
    "                    hab_end = mean(late_hab[(len(late_hab)-4):len(late_hab)]) #calcualte mean of last 4 hab trials\n",
    "\n",
    "                    print(ep, total_loss, hab_start, hab_end)\n",
    "                    if hab_end < (hab_start/2) and ep >= int(hab_min *2): #test if habituated\n",
    "                        break\n",
    "\n",
    "            hab_data[hn,0] =  'skel'\n",
    "            hab_data[hn,1] =  skel[ee][sk]\n",
    "            hab_data[hn,2] =  sf\n",
    "            hab_data[hn,3] =  ep\n",
    "            hab_data[hn,4] =  hab_start\n",
    "            hab_data[hn,5] =  hab_end\n",
    "\n",
    "            print('Saving model', f'Figure_{skel[ee][sk]}_{sf}', ep, hab_start, hab_end)  \n",
    "             \n",
    "            save_model(decoder, ep, optimizer, loss, f'{curr_dir}/Weights/decoder/{exp[ee]}_skel_Figure_{skel[ee][sk]}_{sf}.pt')\n",
    "            np.save(f'{curr_dir}/Weights/decoder/{exp[ee]}_Summary_Skel.npy', hab_data)\n",
    "            hn = hn + 1\n",
    "            del decoder\n",
    "            gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 588.00 MiB (GPU 0; 10.92 GiB total capacity; 10.16 GiB already allocated; 51.38 MiB free; 10.17 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0dbf4c098ca3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m#Load checkpoint from fully trained decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{curr_dir}/Weights/decoder/{ee}_skel_Figure_{sk_hab}_{sf_hab}.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;31m#print(f'Weights/decoder/{exp[ee]}_{hab_data[mm,0]}_Figure_{hab_data[mm,1]}_{hab_data[mm,2]}.pt')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    590\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m    849\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m             \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(data_type, size, key, location)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mstorage_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, non_blocking, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_new\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[0;31m# We may need to call lazy init again if we are a forked child\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[0;31m# del _CudaBase.__new__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CudaBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 588.00 MiB (GPU 0; 10.92 GiB total capacity; 10.16 GiB already allocated; 51.38 MiB free; 10.17 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "'''\n",
    "dishabituate\n",
    "'''\n",
    "\n",
    "\n",
    "for en, ee in enumerate(exp):\n",
    "    \n",
    "    hab_data = np.load(f'{curr_dir}/Weights/decoder/{ee}_Summary_Skel.npy',allow_pickle=True)\n",
    "    \n",
    "\n",
    "#for mm in range(0,1):\n",
    "\n",
    "    #test_data = np.empty(((len(skel[ee]) * len(SF)),hab_data.shape[1]), dtype = object)\n",
    "    \n",
    "    exp_result = []\n",
    "    #habituation index\n",
    "    hn = 0\n",
    "    #load habituated stim\n",
    "    for sk_hab in skel[en]:\n",
    "        for sf_hab in SF:\n",
    "            trial_result = []\n",
    "            torch.cuda.empty_cache() #clear GPU memory\n",
    "            \n",
    "            #Load model\n",
    "            decoder = define_decoder()\n",
    "\n",
    "            #Load checkpoint from fully trained decoder\n",
    "            checkpoint = torch.load(f'{curr_dir}/Weights/decoder/{ee}_skel_Figure_{sk_hab}_{sf_hab}.pt')\n",
    "            #print(f'Weights/decoder/{exp[ee]}_{hab_data[mm,0]}_Figure_{hab_data[mm,1]}_{hab_data[mm,2]}.pt')\n",
    "            decoder.load_state_dict(checkpoint['model_state_dict'])\n",
    "            decoder.eval()\n",
    "            \n",
    "            #load data for dishabituation\n",
    "            for sk_dis in skel[en]:\n",
    "                for sf_dis in SF:\n",
    "                    #load stim for dishab object\n",
    "                    hab_dataset = LoadFrames(f'skels/Figure_{sk_dis}_{sf_dis}', transform=transform)\n",
    "                    trainloader = torch.utils.data.DataLoader(hab_dataset, batch_size=batch_num, shuffle=True, num_workers = 2, pin_memory=True)\n",
    "            \n",
    "\n",
    "                    if sk_hab == sk_dis:\n",
    "                        skel_cat = \"same\"\n",
    "                    else:\n",
    "                        skel_cat = \"diff\"\n",
    "\n",
    "                    if sf_hab == sf_dis:\n",
    "                        sf_cat = \"same\"\n",
    "                    else:\n",
    "                        sf_cat = \"diff\"\n",
    "\n",
    "                    total_loss = []\n",
    "\n",
    "                    for frames in trainloader:\n",
    "                        frames = frames.cuda()\n",
    "\n",
    "                        decode_out = decoder(frames) #Run features through decoder\n",
    "\n",
    "                        loss = criterion(decode_out, frames) #Calculate loss\n",
    "                        train_loss += (loss.item()*frames.size(0))\n",
    "                        n = n +1\n",
    "\n",
    "                        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "                        #loss.backward()\n",
    "                        # perform a single optimization step (parameter update)\n",
    "                        #optimizer.step()                        \n",
    "\n",
    "                        #print(train_loss, loss.item()*frames.size(0), n)\n",
    "                    total_loss = train_loss/n\n",
    "                    dishab_trial = hab_data[hn,:6].tolist() + [sk_dis, sf_dis, skel_cat, sf_cat, total_loss]\n",
    "                    print(dishab_trial)\n",
    "                    trial_result.append(dishab_trial)\n",
    "                    exp_result.append(dishab_trial)\n",
    "\n",
    "                    #print(ep, total_loss)\n",
    "\n",
    "                    '''\n",
    "                    if skel_cat == 'same' and sf_cat == 'same':\n",
    "                        save_recon(decode_out, skel_cat, sf_cat, hab_data[hn,0],f'Figure_{hab_data[hn,1]}_{hab_data[hn,2]}')\n",
    "                    '''\n",
    "\n",
    "            #print(trial_result)\n",
    "            hn = hn +1\n",
    "            np.savetxt(f'{curr_dir}/Results/AE/{ee}_{hab_data[hn,0]}_Figure_{hab_data[hn,1]}_{hab_data[hn,2]}_Result.csv', np.array(trial_result), delimiter=',', fmt= '%s')\n",
    "            del decoder\n",
    "            gc.collect()\n",
    "            \n",
    "    \n",
    "    \n",
    "    np.savetxt(f'{curr_dir}/Results/AE/{ee}_Skel_Result.csv', np.array(exp_result), delimiter=',', fmt= '%s')\n",
    "            \n",
    "    #hn = hn + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "skel_cat  sf_cat\n",
       "diff      diff      2.521176\n",
       "          same      2.539957\n",
       "same      diff      2.449618\n",
       "          same      2.477809\n",
       "Name: loss, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.array(exp_result), columns = ['model','skel_hab','sf_hab', 'trials', 'hab_start', 'hab_end', 'skel_dishab', 'sf_dishab', 'skel_cat', 'sf_cat', 'loss'])\n",
    "df['loss'] = pd.to_numeric(df['loss'])\n",
    "\n",
    "df.groupby(['skel_cat', 'sf_cat'])['loss'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk = '23'\n",
    "sf = 'Skel'\n",
    "model = 'ResNet_SN'\n",
    "ee = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk = hab_data[mm,1]\n",
    "sf = hab_data[mm,2]\n",
    "model = hab_data[mm,0]\n",
    "ee = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, in_feat = load_model(model) #load encoder\n",
    "encoder.cuda()\n",
    "encoder.eval()\n",
    "#Create decoder\n",
    "#it gets reset for every object\n",
    "decoder = nn.Sequential(nn.ReLU(), nn.ConvTranspose2d(in_feat, 3, 224))\n",
    "decoder = decoder.cuda()\n",
    "\n",
    "#Load checkpoint from fully trained decoder\n",
    "checkpoint = torch.load(f'Weights/decoder/{exp[ee]}_{model}_Figure_{sk}_{sf}.pt')\n",
    "decoder.load_state_dict(checkpoint)\n",
    "decoder.eval()\n",
    "decoder.train()\n",
    "optimizer = torch.optim.Adam(decoder.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hab_dataset = LoadFrames(f'Frames/Figure_{sk}_{sf}', transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(hab_dataset, batch_size=batch_num, shuffle=True, num_workers = 0, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = 0.0 \n",
    "n = 0\n",
    "for frames in trainloader:\n",
    "    frames = frames.cuda()\n",
    "\n",
    "\n",
    "    encode_out = encoder(frames) #Get encoder features\n",
    "\n",
    "    optimizer.zero_grad() #zero out gradients from previous epoch\n",
    "\n",
    "    decode_out = decoder(encode_out) #Run features through decoder\n",
    "\n",
    "    loss = criterion(decode_out, frames) #Calculate loss\n",
    "    print((loss.item()*frames.size(0)))\n",
    "    train_loss += (loss.item()*frames.size(0))\n",
    "    n = n +1\n",
    "\n",
    "\n",
    "    # backward pass: compute gradient of the loss with respect to model parameters\n",
    "    #loss.backward()\n",
    "    # perform a single optimization step (parameter update)\n",
    "    #optimizer.step()\n",
    "    optimizer.zero_grad() #zero out gradients from previous epoch\n",
    "\n",
    "\n",
    "\n",
    "    #print(train_loss, loss.item()*frames.size(0), n)\n",
    "print(train_loss/n)\n",
    "\n",
    "#print(ep, total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = transforms.Resize((224, 224))\n",
    "#normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                 std=[0.229, 0.224, 0.225])\n",
    "#to_tensor = transforms.ToTensor()\n",
    "def image_loader(image_name):\n",
    "    \"\"\"load image, returns cuda tensor\"\"\"\n",
    "    image = Image.open(image_name).convert(\"RGB\")\n",
    "    #image = Variable(normalize(to_tensor(scaler(image))).unsqueeze(0))\n",
    "    image = transform(image).unsqueeze(0)\n",
    "    \n",
    "    return image     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load sample image\n",
    "IM = image_loader(f'Frames/Figure_{sk}_{sf}/Figure_{sk}_{sf}_150.jpg')\n",
    "IM = IM.cuda()\n",
    "print(IM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Weights/decoder/{exp[ee]}_{model}_Figure_{sk}_{sf}.pt')\n",
    "print(IM.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out = encoder(IM)\n",
    "out = decoder(out)\n",
    "loss = criterion(out, IM)\n",
    "print(loss.item()*IM.size(0))\n",
    "#out = out.squeeze(0)\n",
    "#print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here on is image preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out.squeeze(0)\n",
    "print(out.shape)\n",
    "inv_normalize = transforms.Normalize(\n",
    "   mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
    "   std=[1/0.229, 1/0.224, 1/0.225]\n",
    ")\n",
    "\n",
    "output = inv_normalize(out)\n",
    "output = output.cpu().detach()\n",
    "plt.imshow(output.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM = IM.squeeze(0)\n",
    "IM = inv_normalize(IM)\n",
    "IM = IM.cpu().detach()\n",
    "plt.imshow(IM.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here on is image preview"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
