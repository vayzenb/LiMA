{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dir = '/user_data/vayzenbe/GitHub_Repos/LiMA'\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, f'{curr_dir}')\n",
    "import os, argparse\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "from LoadFrames import LoadFrames\n",
    "from statistics import mean\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import pandas as pd\n",
    "import pdb\n",
    "from itertools import chain\n",
    "import deepdish as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exp = ['Exp1', 'Exp2']\n",
    "\n",
    "skel = [['31'],['31_50']]\n",
    "SF = [ 'Skel']\n",
    "modelType = ['skel']\n",
    "\n",
    "batch_num = 1\n",
    "n_frames = 300\n",
    "\n",
    "#Transformations for ImageNet\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                             std=[0.229, 0.224, 0.225])])\n",
    "inv_normalize = transforms.Normalize(\n",
    "   mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],std=[1/0.229, 1/0.224, 1/0.225])\n",
    "# specify loss function\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "hab_min = 4 #minimum number of habituation trials\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_decoder(act_num):\n",
    "    decoder = nn.Sequential(nn.Conv2d(3,act_num,kernel_size=3, stride=2), nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2, padding=1), nn.AdaptiveAvgPool2d(1),nn.ReLU(), nn.ConvTranspose2d(act_num, 3, 224))\n",
    "    decoder = decoder.cuda()\n",
    "    \n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_model(modelType_):\n",
    "    global stim_dir\n",
    "    #select model to run\n",
    "    if modelType_ == 'pixel1':\n",
    "        #model = nn.Sequential(nn.Conv2d(3,1024,kernel_size=3, stride=2), nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2, padding=1), nn.AdaptiveAvgPool2d(1))\n",
    "        act_num = 1024\n",
    "        stim_dir = f'{curr_dir}/Frames'\n",
    "        \n",
    "\n",
    "    elif modelType_ == 'skel':\n",
    "        #model = nn.Sequential(nn.Conv2d(3,4096,kernel_size=3, stride=2), nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2, padding=1), nn.AdaptiveAvgPool2d(1))\n",
    "        act_num = 1024\n",
    "        stim_dir = f'{curr_dir}/Frames'\n",
    "\n",
    "    decoder = define_decoder(act_num)\n",
    "    \n",
    "    return decoder, act_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_recon(out_, model, stim):\n",
    "    \n",
    "    fig,ax = plt.subplots(1)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    # Show the image\n",
    "    #ax.imshow(im)\n",
    "\n",
    "    out_ = out_.squeeze(0)\n",
    "    out_ = inv_normalize(out_)\n",
    "    out_ = out_.cpu().detach()\n",
    "    ax.imshow(out_.permute(1, 2, 0))\n",
    "    plt.axis('off')\n",
    "    #print(f'Results/AE/recon/{model}_{fig_fig_}.png')\n",
    "    plt.savefig(f'{curr_dir}/Results/AE/recon/{model}_{stim}.png', bbox_inches='tight', pad_inches = 0, dpi=150)\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_recon(exp, model_type):\n",
    "\n",
    "    '''\n",
    "    Load each habituated model for one object and tests dishabituation for every other object\n",
    "    \n",
    "    '''\n",
    "    print('Creating recons...')\n",
    "\n",
    "    #load habituated stim\n",
    "    for sk_hab in skel[exp[0]]:\n",
    "        for sf_hab in SF:\n",
    "            trial_result = []\n",
    "            torch.cuda.empty_cache() #clear GPU memory\n",
    "            \n",
    "            #Load model\n",
    "            decoder, act_num = load_model(model_type)\n",
    "\n",
    "            #Load checkpoint from fully trained decoder\n",
    "            checkpoint = torch.load(f'{curr_dir}/Weights/decoder/{exp[1]}_{model_type}_Figure_{sk_hab}_{sf_hab}.pt')\n",
    "            #print(f'Weights/decoder/{exp[ee]}_{hab_data[mm,0]}_Figure_{hab_data[mm,1]}_{hab_data[mm,2]}.pt')\n",
    "            decoder.load_state_dict(checkpoint['model_state_dict'])\n",
    "            decoder.eval()\n",
    "            \n",
    "            #load stim for dishab object\n",
    "            hab_dataset = LoadFrames(f'{stim_dir}/Figure_{sk_hab}_{sf_hab}', transform=transform)\n",
    "            trainloader = torch.utils.data.DataLoader(hab_dataset, batch_size=batch_num, shuffle=True)\n",
    "\n",
    "            #pdb.set_trace()\n",
    "            for frames in trainloader:\n",
    "                frames = frames.cuda()\n",
    "\n",
    "                decode_out = decoder(frames) #Run features through decoder\n",
    "                save_recon(decode_out, model_type,f'Figure_{sk_hab}_{sf_hab}')\n",
    "                \n",
    "                break #exit out of recon loop after running one batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating recons...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating recons...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    }
   ],
   "source": [
    "for ee in enumerate(exp):\n",
    "    for mm in modelType:\n",
    "        run_recon(ee,mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a73dd579cb98b653d7ecde1e422adf56bab516ece8948c409c82164c3a4ed8cd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
