{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses an autoencoder to approximate the habituation/dishabituation process\n",
    "An autoencoder is afixed ontop of the pre-trained model \n",
    "LiMA stim are run through it\n",
    "\n",
    "Author: VAYZENB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dir = '/home/vayzenbe/GitHub_Repos/LiMA'\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, f'{curr_dir}')\n",
    "import os, argparse\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "from LoadFrames import LoadFrames\n",
    "from statistics import mean\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ['Exp1']\n",
    "\n",
    "skel = [['23','31', '26'],['31_0', '31_50']]\n",
    "SF = ['Skel', 'Bulge']\n",
    "modelType = 'skel'\n",
    "\n",
    "hab_min = 4 #minimum number of habituation trials to \n",
    "batch_num = 10 #how many frames to use at a time\n",
    "#exp = ['Exp2']\n",
    "#skel=[['26']]\n",
    "#SF = ['Bulge']\n",
    "#modelType = ['SayCam']\n",
    "\n",
    "#Transformations for ImageNet\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                             std=[0.229, 0.224, 0.225])])\n",
    "# specify loss function\n",
    "criterion = nn.MSELoss()\n",
    "#criterion.cuda()\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_decoder():\n",
    "    decoder = nn.Sequential(nn.Conv2d(3,1024,kernel_size=3, stride=2), nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2, padding=1), nn.AdaptiveAvgPool2d(1),\n",
    "    nn.ReLU(), nn.ConvTranspose2d(1024, 3, 224))\n",
    "    decoder = decoder.cuda()\n",
    "    \n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, epoch, optimizer, loss, file_path):\n",
    "\n",
    "    print('Saving model ...')\n",
    "    #torch.save(model.state_dict(), f'{weights_dir}/cornet_classify_{cond}_{epoch}.pt')\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "        }, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 57.40652839342753\n",
      "1 24.963297446568806\n",
      "2 17.651907404263813\n",
      "3 3.620086361964544\n",
      "4 7.717233498891194 25.91045490155617 7.717233498891194\n",
      "5 2.5537021458148956 25.91045490155617 5.1354678223530446\n",
      "6 4.870673616727193 25.91045490155617 4.870673616727193\n",
      "7 1.4866910378138225 25.91045490155617 4.157075074811776\n",
      "8 2.4608607590198517 25.91045490155617 2.8429818898439407\n",
      "Saving model Figure_23_Skel 8 25.91045490155617 2.8429818898439407\n",
      "Saving model ...\n",
      "0 32.189510787526764\n",
      "1 11.24430219332377\n",
      "2 3.3685445288817086\n",
      "3 5.124305586020152\n",
      "4 1.3386002431313198 12.981665773938097 1.3386002431313198\n",
      "5 3.136986792087555 12.981665773938097 2.2377935176094375\n",
      "6 0.9127996861934662 12.981665773938097 0.9127996861934662\n",
      "7 1.6446622709433238 12.981665773938097 1.7582622480889163\n",
      "8 0.803921731809775 12.981665773938097 1.62459262025853\n",
      "Saving model Figure_23_Bulge 8 12.981665773938097 1.62459262025853\n",
      "Saving model ...\n",
      "0 43.50017165144285\n",
      "1 17.702496846516926\n",
      "2 10.02119223276774\n",
      "3 4.734996284047763\n",
      "4 2.8842360402146974 18.989714253693823 2.8842360402146974\n",
      "5 2.913424869378408 18.989714253693823 2.8988304547965527\n",
      "6 2.1562808007001877 18.989714253693823 2.1562808007001877\n",
      "7 1.450016771753629 18.989714253693823 2.3509896205117307\n",
      "8 1.2488649785518646 18.989714253693823 1.9421468550960224\n",
      "Saving model Figure_31_Skel 8 18.989714253693823 1.9421468550960224\n",
      "Saving model ...\n",
      "0 30.46049339075883\n",
      "1 10.810045997301737\n",
      "2 2.9578505953152976\n",
      "3 4.786390066146851\n",
      "4 1.7582440003752708 12.25369501238068 1.7582440003752708\n",
      "5 2.6496827602386475 12.25369501238068 2.203963380306959\n",
      "6 1.2712470442056656 12.25369501238068 1.2712470442056656\n",
      "7 1.21292798469464 12.25369501238068 1.723025447378556\n",
      "8 1.1483218024174373 12.25369501238068 1.5705448978890977\n",
      "Saving model Figure_31_Bulge 8 12.25369501238068 1.5705448978890977\n",
      "Saving model ...\n",
      "0 40.41787271698316\n",
      "1 15.447996060053507\n",
      "2 7.681346883376439\n",
      "3 4.83622948328654\n",
      "4 2.4588746453324952 17.09586128592491 2.4588746453324952\n",
      "5 3.248166640599569 17.09586128592491 2.853520642966032\n",
      "6 2.0676669478416443 17.09586128592491 2.0676669478416443\n",
      "7 1.6337731232245762 17.09586128592491 2.3521203392495713\n",
      "8 1.1030135676264763 17.09586128592491 2.0131550698230662\n",
      "Saving model Figure_26_Skel 8 17.09586128592491 2.0131550698230662\n",
      "Saving model ...\n",
      "0 39.06987823545933\n",
      "1 15.78752875328064\n",
      "2 6.925316552321116\n",
      "3 5.008803655703862\n",
      "4 1.9738682111104329 16.697881799191236 1.9738682111104329\n",
      "5 3.3606427907943726 16.697881799191236 2.6672555009524026\n",
      "6 1.6518034785985947 16.697881799191236 1.6518034785985947\n",
      "7 1.6743654757738113 16.697881799191236 2.165169989069303\n",
      "8 0.8772679915030798 16.697881799191236 1.8910199341674645\n",
      "Saving model Figure_26_Bulge 8 16.697881799191236 1.8910199341674645\n",
      "Saving model ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for ee in range(0,len(exp)):\n",
    "    hab_data = np.empty(((len(skel[ee]) * len(SF) *len(modelType)),11), dtype = object)\n",
    "    hn = 0\n",
    "\n",
    "\n",
    "    for sk in range(0,len(skel[ee])):\n",
    "        for sf in SF:\n",
    "            torch.cuda.empty_cache() #clear GPU memory\n",
    "            hab_dataset = LoadFrames(f'skels/Figure_{skel[ee][sk]}_{sf}', transform=transform)\n",
    "            trainloader = torch.utils.data.DataLoader(hab_dataset, batch_size=batch_num, shuffle=True, num_workers = 2, pin_memory=True)\n",
    "\n",
    "            early_hab = 0.0\n",
    "            late_hab = []\n",
    "\n",
    "            #Reset decoder for every object (i.e., make it like a fresh hab session)\n",
    "            #Create decoder\n",
    "            decoder = define_decoder()\n",
    "            decoder.eval()\n",
    "            decoder.train()\n",
    "\n",
    "            #set up optimzer\n",
    "            optimizer = torch.optim.Adam(decoder.parameters(), lr=0.01)\n",
    "            for ep in range(0,epochs):\n",
    "                train_loss = 0.0 \n",
    "                total_loss =0.0\n",
    "                n = 0\n",
    "                for frames in trainloader:\n",
    "                    frames = frames.cuda()\n",
    "\n",
    "\n",
    "                    optimizer.zero_grad() #zero out gradients from previous epoch\n",
    "\n",
    "                    decode_out = decoder(frames) #Run features through decoder\n",
    "\n",
    "                    loss = criterion(decode_out, frames) #Calculate loss\n",
    "\n",
    "                    # backward pass: compute gradient of the loss with respect to model parameters\n",
    "                    loss.backward()\n",
    "                    # perform a single optimization step (parameter update)\n",
    "                    optimizer.step()\n",
    "\n",
    "\n",
    "                    train_loss += (loss.item()*frames.size(0))\n",
    "                    n = n +1\n",
    "                    #print(train_loss, loss.item()*frames.size(0), n)\n",
    "\n",
    "                total_loss = train_loss/n\n",
    "\n",
    "                if ep < hab_min:\n",
    "                    early_hab += total_loss #track loss for the first 4 trials\n",
    "                    print(ep, total_loss)\n",
    "                elif ep >= hab_min:\n",
    "                    hab_start = early_hab / hab_min #Determine habituation criterion\n",
    "                    late_hab.append(total_loss) #add current loss to habituation\n",
    "                    hab_end = mean(late_hab[(len(late_hab)-4):len(late_hab)]) #calcualte mean of last 4 hab trials\n",
    "\n",
    "                    print(ep, total_loss, hab_start, hab_end)\n",
    "                    if hab_end < (hab_start/2) and ep >= int(hab_min *2): #test if habituated\n",
    "                        break\n",
    "\n",
    "            hab_data[hn,0] =  'skel'\n",
    "            hab_data[hn,1] =  skel[ee][sk]\n",
    "            hab_data[hn,2] =  sf\n",
    "            hab_data[hn,3] =  ep\n",
    "            hab_data[hn,4] =  hab_start\n",
    "            hab_data[hn,5] =  hab_end\n",
    "\n",
    "            print('Saving model', f'Figure_{skel[ee][sk]}_{sf}', ep, hab_start, hab_end)  \n",
    "             \n",
    "            save_model(decoder, ep, optimizer, loss, f'{curr_dir}/Weights/decoder/{exp[ee]}_skel_Figure_{skel[ee][sk]}_{sf}.pt')\n",
    "            np.save(f'{curr_dir}/Weights/decoder/{exp[ee]}_Summary_Skel.npy', hab_data)\n",
    "            hn = hn + 1\n",
    "            del decoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here on is image preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here on is image preview"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
