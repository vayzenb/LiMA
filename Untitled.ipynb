{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses an autoencoder to approximate the habituation/dishabituation process\n",
    "An autoencoder is afixed ontop of the pre-trained model \n",
    "LiMA stim are run through it\n",
    "\n",
    "Author: VAYZENB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dependancies\n",
    "import os\n",
    "#os.chdir('C:/Users/vayze/Desktop/GitHub Repos/LiMA/')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.models\n",
    "#import torchvision.transforms as T\n",
    "#from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "from itertools import chain\n",
    "import deepdish as dd\n",
    "import cornet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ['Exp1', 'Exp2']\n",
    "\n",
    "skel = [['23','31', '26'],['31_0', '31_50']]\n",
    "SF = ['Skel', 'Bulge', 'Balloon', 'Shrink', 'Wave']\n",
    "modelType = ['SayCam','CorNet_Z', 'CorNet_S','AlexNet_SN', 'ResNet_SN', 'AlexNet_IN', 'ResNet_IN']\n",
    "modelType = ['ResNet_IN']\n",
    "\n",
    "#Transformations for ImageNet\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                             std=[0.229, 0.224, 0.225])])\n",
    "# specify loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#Gets feats for CorNet models\n",
    "def _store_feats(layer, inp, output):\n",
    "    \"\"\"An ugly but effective way of accessing intermediate model features\n",
    "    \"\"\"   \n",
    "    output = output.cpu().detach().numpy()\n",
    "    #_model_feats.append(np.reshape(output, (len(output), -1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(modelType_):\n",
    "    #select model to run\n",
    "    if modelType_ == 'AlexNet_IN':\n",
    "        model = torchvision.models.alexnet(pretrained=True)\n",
    "        new_classifier = nn.Sequential(*list(model.classifier.children())[:-1])\n",
    "        model.classifier = new_classifier #replace model classifier with stripped version\n",
    "        layer = \"fc7\"\n",
    "        actNum = 4096\n",
    "        \n",
    "    elif modelType_ == 'ResNet_IN':\n",
    "        model = torchvision.models.resnet50(pretrained=True)\n",
    "        model = nn.Sequential(*list(model.children())[:-1])\n",
    "        layer = \"avgpool\"\n",
    "        actNum = 2048\n",
    "                \n",
    "    elif modelType_ == 'AlexNet_SN':\n",
    "        model = torchvision.models.alexnet(pretrained=False)\n",
    "        checkpoint = torch.load('Weights/ShapeNet_AlexNet_Weights.pth.tar')\n",
    "        model.load_state_dict(checkpoint)\n",
    "        new_classifier = nn.Sequential(*list(model.classifier.children())[:-1])\n",
    "        model.classifier = new_classifier #replace model classifier with stripped version\n",
    "        layer = \"fc7\"\n",
    "        actNum = 4096\n",
    "        \n",
    "    elif modelType_ == 'ResNet_SN':\n",
    "        model = torchvision.models.resnet50(pretrained=False)\n",
    "        checkpoint = torch.load('Weights/ShapeNet_ResNet50_Weights.pth.tar')\n",
    "        model.load_state_dict(checkpoint)\n",
    "        model = nn.Sequential(*list(model.children())[:-1])\n",
    "        \n",
    "        layer = \"avgpool\"\n",
    "        actNum = 2048\n",
    "    \n",
    "    elif modelType_ == 'CorNet_Z':\n",
    "        model = getattr(cornet, 'cornet_z')\n",
    "        model = model(pretrained=False, map_location='gpu')\n",
    "        \n",
    "        layer = \"avgpool\"\n",
    "        actNum = 512\n",
    "    \n",
    "        try:\n",
    "            m = model.module\n",
    "        except:\n",
    "            m = model\n",
    "        model_layer = getattr(getattr(m, 'decoder'), layer)\n",
    "        model_layer.register_forward_hook(_store_feats)\n",
    "\n",
    "    elif modelType[mm] == 'CorNet_S':\n",
    "        model = getattr(cornet, 'cornet_s')\n",
    "        model = model(pretrained=False, map_location='gpu')\n",
    "        \n",
    "        layer = \"avgpool\"\n",
    "        actNum = 512        \n",
    "\n",
    "        try:\n",
    "            m = model.module\n",
    "        except:\n",
    "            m = model\n",
    "        \n",
    "        model_layer = getattr(getattr(m, 'decoder'), layer)\n",
    "        model_layer.register_forward_hook(_store_feats)\n",
    "\n",
    "    elif modelType[mm] == 'SayCam':\n",
    "        model = torchvision.models.resnext50_32x4d(pretrained=False)\n",
    "        model = torch.nn.DataParallel(model)\n",
    "        #model.fc = torch.nn.Linear(in_features=2048, out_features=n_out, bias=True)\n",
    "        checkpoint = torch.load('Weights/SayCam_ResNext_Weights.pth.tar')\n",
    "        model.load_state_dict(checkpoint)\n",
    "        \n",
    "        actNum = 512\n",
    "\n",
    "        model = nn.Sequential(*list(model.children())[:-1])\n",
    "        \n",
    "        return model, actNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for mm in range(0, len(modelType)):\n",
    "    encoder, in_feat = load_model(modelType[mm])\n",
    "    #Create decoder\n",
    "    decoder = nn.Sequential(nn.ReLU(), nn.ConvTranspose2d(in_feat, 3, 224))\n",
    "    \n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "    \n",
    "    #set up optimzer\n",
    "    optimizer = torch.optim.Adam(decoder.parameters(), lr=0.01)\n",
    "    \n",
    "    for sk in range(0,len(skel[ee])):\n",
    "        for sf in SF:\n",
    "            hab_dataset = datasets.ImageFolder(f'Frames/Figure_{skel[ee][ss]}_{sf}', transform=transform)\n",
    "            trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=len(hab_dataset), shuffle=False, num_workers = 4, pin_memory=True)\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
